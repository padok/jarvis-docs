
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="../../assets/images/logo_color.svg" rel="icon"/>
<meta content="mkdocs-1.3.1, mkdocs-material-8.4.0" name="generator"/>
<title>2. Exploring the Example Trainingset - JARVIS Mocap -  Documentation</title>
<link href="../../assets/stylesheets/main.69437709.min.css" rel="stylesheet"/>
<link href="../../assets/stylesheets/palette.cbb835fc.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../stylesheets/extra.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>html.glightbox-open { overflow: initial; height: 100%; }</style><script src="../../assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="" data-md-color-primary="" data-md-color-scheme="slate" dir="ltr">
<script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#exploring-the-provided-example-trainingset">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="JARVIS Mocap -  Documentation" class="md-header__button md-logo" data-md-component="logo" href="../.." title="JARVIS Mocap -  Documentation">
<img alt="logo" src="../../assets/images/logo.png"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            JARVIS Mocap -  Documentation
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              2. Exploring the Example Trainingset
            
          </span>
</div>
</div>
</div>
<form class="md-header__option" data-md-component="palette">
<input aria-label="Switch to light mode" class="md-option" data-md-color-accent="" data-md-color-media="" data-md-color-primary="" data-md-color-scheme="slate" id="__palette_1" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_2" hidden="" title="Switch to light mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"></path></svg>
</label>
<input aria-label="Switch to dark mode" class="md-option" data-md-color-accent="" data-md-color-media="" data-md-color-primary="" data-md-color-scheme="default" id="__palette_2" name="__palette" type="radio"/>
<label class="md-header__button md-icon" for="__palette_1" hidden="" title="Switch to dark mode">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"></path></svg>
</label>
</form>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/JARVIS-MoCap" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.1.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="JARVIS Mocap -  Documentation" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="JARVIS Mocap -  Documentation">
<img alt="logo" src="../../assets/images/logo.png"/>
</a>
    JARVIS Mocap -  Documentation
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/JARVIS-MoCap" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.1.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../..">
        Home
      </a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="__nav_2" id="__nav_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2">
          Getting Started
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Getting Started" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
          Getting Started
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../1_introduction/">
        1. Introduction
      </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
          2. Exploring the Example Trainingset
          <span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
        2. Exploring the Example Trainingset
      </a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#1-installing-the-toolbox-and-downloading-the-data">
    1. Installing the Toolbox and Downloading the Data
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#2-visualizing-the-example-trainingset">
    2. Visualizing the Example Trainingset
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#3-training-the-entire-network">
    3. Training the Entire Network
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#4-predicting-poses-for-the-example-recording">
    4. Predicting Poses for the Example Recording
  </a>
<nav aria-label="4. Predicting Poses for the Example Recording" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#5-creating-annotated-videos-from-your-predictions">
    5. Creating Annotated Videos from Your Predictions
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../3_creating_trainingset/">
        3. Creating a new Trainingset
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_3" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3">
          Manual
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Manual" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
          Manual
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../manual/1_introduction/">
        1. Introduction
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../manual/2_mocap_setup_design/">
        2. Designing a Setup
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../manual/3_acquisitiontool_setup/">
        3. Setting up the AcquisitionTool
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../manual/4_recording_calibration/">
        4. Recording Calibration Videos
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../manual/5_creating_and_labeling_datasts/">
        5. Creating and Labeling Datasets
      </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../model_database/model_database/">
        Model Database
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../downloads/downloads/">
        Downloads
      </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" id="__nav_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_6">
          Developer Documentation
          <span class="md-nav__icon md-icon"></span>
</label>
<nav aria-label="Developer Documentation" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_6">
<span class="md-nav__icon md-icon"></span>
          Developer Documentation
        </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../developer_documentation/1_introduction/">
        1. Introduction
      </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../developer_documentation/9_trigger/">
        9. Trigger
      </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#1-installing-the-toolbox-and-downloading-the-data">
    1. Installing the Toolbox and Downloading the Data
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#2-visualizing-the-example-trainingset">
    2. Visualizing the Example Trainingset
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#3-training-the-entire-network">
    3. Training the Entire Network
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#4-predicting-poses-for-the-example-recording">
    4. Predicting Poses for the Example Recording
  </a>
<nav aria-label="4. Predicting Poses for the Example Recording" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#5-creating-annotated-videos-from-your-predictions">
    5. Creating Annotated Videos from Your Predictions
  </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<h1 id="exploring-the-provided-example-trainingset">Exploring the Provided Example Trainingset</h1>
<p>Let's start by playing around with our provided example so you can familiarize with our software and get a better feel for the task and the workflow.<br/>
The example data we're working with in this tutorial are recordings of one of our monkeys performing a simple grasping task in our 12 camera setup. Your task is to track his hand while he is enjoying a variety of fruits we hand him.
We will split the task into four steps:</p>
<ol>
<li><span style="color:#63a31f"><b>Installing</b></span> our <strong>Pytorch Toolbox</strong> and downloading the example recordings.</li>
<li><span style="color:#63a31f"><b>Visualizing</b></span> the provided annotations, both in 2D and 3D.</li>
<li><span style="color:#63a31f"><b>Training</b></span> the entire network stack.</li>
<li><span style="color:#63a31f"><b>Predicting Poses</b></span> for the Example Recording.</li>
<li><span style="color:#63a31f"><b>Creating Annotated Videos</b></span> from Your Predictions.</li>
</ol>
<h2 id="1-installing-the-toolbox-and-downloading-the-data">1. Installing the Toolbox and Downloading the Data</h2>
<p>First let's take care of setting up the software. Make sure you have a version of <a href="https://www.anaconda.com/">Anaconda</a> installed. If you want to train networks also make sure that your PC has a Nvidia GPU with working CUDA drivers installed.<br/>
There are only a few simple steps you need to take to install the toolbox:
- Download the python package. To do this open up a terminal and run:
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a>git clone https://github.com/JARVIS-MoCap/JARVIS-HybridNet.git &amp;&amp; cd JARVIS-HybridNet
</code></pre></div>
Alternatively you download it directly by clicking <a href="https://github.com/JARVIS-MoCap/JARVIS-HybridNet/archive/refs/heads/master.zip">here</a>.</p>
<ul>
<li>
<p>Create the <code>jarvis</code> Anaconda environment by running:
<div class="highlight"><pre><span></span><code><a href="#__codelineno-1-1" id="__codelineno-1-1" name="__codelineno-1-1"></a>conda create -n jarvis python=3.9  pytorch=1.10.1 torchvision cudatoolkit=11.3 notebook  -c pytorch
</code></pre></div></p>
</li>
<li>
<p>Activate the environment (you will need to do this every time you open a terminal to use JARVIS):
<div class="highlight"><pre><span></span><code><a href="#__codelineno-2-1" id="__codelineno-2-1" name="__codelineno-2-1"></a>conda activate jarvis
</code></pre></div></p>
</li>
<li>
<p>Install the required version of the setuptools package:
<div class="highlight"><pre><span></span><code><a href="#__codelineno-3-1" id="__codelineno-3-1" name="__codelineno-3-1"></a>pip install -U setuptools==59.5.0
</code></pre></div></p>
</li>
<li>
<p>Install JARVIS:
<div class="highlight"><pre><span></span><code><a href="#__codelineno-4-1" id="__codelineno-4-1" name="__codelineno-4-1"></a>pip install -e .
</code></pre></div></p>
</li>
</ul>
<p>With that out of the way the only thing left to do is downloading the example recordings by clicking <a href="https://zenodo.org/record/6515085/files/Example_Recording.zip?download=1">here</a>.<br/>
<br/>
<img alt="🎉" class="twemoji" src="https://twemoji.maxcdn.com/v/latest/svg/1f389.svg" title=":tada:"> Congratulations, you are all set up now! To launch our handy streamlit GUI interface just open a terminal, activate the conda environment by running <code>conda activate jarvis</code> and type <code>jarvis launch</code>.<br/> 
Alternatively you can also interact with jarvis through the command line. To do this activate the conda environment and then run <code>jarvis launch-cli</code>. The following sections give you the option to switch between instructions for both methods by selecting the respective tabs.
<br/></img></p>
<h2 id="2-visualizing-the-example-trainingset">2. Visualizing the Example Trainingset</h2>
<p>Before we dive into training JARVIS to track anything it is always a good idea to have a look at the trainingset your are using, both in 2D and in 3D.<br/></p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:2"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio"><input id="__tabbed_1_2" name="__tabbed_1" type="radio"><div class="tabbed-labels"><label for="__tabbed_1_1">GUI</label><label for="__tabbed_1_2">CLI</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>To do this using the streamlit dashboard first launch the JARVIS streamlit dashboard as described above by running <code>jarvis launch</code>. Once the GUI pops up in your browser you can select the Example_Project from the drop-down menu and then navigate to the visualization menu.<br/></p>
<p><a class="glightbox" href="../../assets/gifs/getting_started/dataset_vis_gui.gif"><img alt="Dataset visualization using the GUI" class="center rounded" src="../../assets/gifs/getting_started/dataset_vis_gui.gif" width="90%"/></a></p>
<p>As you can see there are a bunch of option for visualizing both your predictions and your trainingset. You can see how that looks like above, but feel free to play around with it a bit to familiarize yourself with the data you are working with.</p>
</div>
<div class="tabbed-block">
<p>To do this using the command line interface first launch it by running <span style="color:#63a31f">'jarvis launch-cli'</span>. You will see a menu appear in your terminal that you can navigate using your arrow keys. To visualize your dataset select the <span style="color:#63a31f">Visualize</span> menu and then pick either the <span style="color:#63a31f">Dataset2D</span> or the <span style="color:#63a31f">Dataset2D</span> option.<br/></p>
<p><a class="glightbox" href="../../assets/gifs/getting_started/cli_vis_dataset.gif"><img alt="Dataset visualization using the CLI" class="center rounded" src="../../assets/gifs/getting_started/cli_vis_dataset.gif" width="90%"/></a></p>
<p>To visualize the example trainingset select the 'Example_Project' and the 'Hand' skeleton preset. Other than that feel free to play around with the different options.You can cycle through all the available frames by pressing any key. Pressing 'q' or 'esc' will take you back to the Visualize menu.</p>
</div>
</div>
</input></input></div>
<p>Once you start working with your own data, checking your trainingset before training is really important to ensure there was no problem when creating it and your network will get the input you expect it to get.</p>
<h2 id="3-training-the-entire-network">3. Training the Entire Network</h2>
<p>Now that you know what our data looks like it is time to train the network stack.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:2"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio"><input id="__tabbed_2_2" name="__tabbed_2" type="radio"><div class="tabbed-labels"><label for="__tabbed_2_1">GUI</label><label for="__tabbed_2_2">CLI</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>Using our GUI this is really easy, all you need to do is to navigate to the <span style="color:#63a31f">Train Full</span> menu and press train as shown below. If everything works correctly you should see two progress bars as well as a plot showing the training progress appear. Depending on your GPU training might take up to a few hours, so a bit of patience is required at this point. If you don't want to wait you can also continue with our pretrained weights of course.</p>
<p><a class="glightbox" href="../../assets/images/getting_started/Training_Screenshot.png"><img alt="Training using the GUI" class="center rounded" src="../../assets/images/getting_started/Training_Screenshot.png" width="90%"/></a></p>
</div>
<div class="tabbed-block">
<p>The CLI makes this very easy. All you need to do is launch the interface by running <code>jarvis launch-cli</code>, select the <span style="color:#63a31f">Train</span> menu and then run <span style="color:#63a31f">Train all</span> as shown below. If everything works correctly you should see a progress bar appearing. Depending on your GPU training might take up to a few hours, so a bit of patience is required at this point. If you don't want to wait you can also continue with our pretrained weights of course.</p>
<p><a class="glightbox" href="../../assets/gifs/getting_started/cli_train.gif"><img alt="Dataset visualization using the CLI" class="center rounded" src="../../assets/gifs/getting_started/cli_train.gif" width="90%"/></a></p>
</div>
</div>
</input></input></div>
<details class="info">
<summary>More Info on Network Training</summary>
<p>Our network stack is trained in four steps:</p>
<ol>
<li><strong>Training CenterDetect:</strong> In this step a 2D-CNN is trained to detect the center of the entity you are tracking. This will be used to estimate the location of the entity in 3D, essentially telling the 3D-CNN where to look.</li>
<li><strong>Training KeypointDetect:</strong> In this step another 2D-CNN is trained to detect all your annotated keypoints in a single image. The output of this network will subsequently be used to construct the 3D feature volume that is the input of our 3D-CNN. </li>
<li><strong>Training HybridNet:</strong> In this step the 3D part of our full HybridNet architecture is trained. It's job is to use the 3D feature volumes created by the KeypointDetect stage to create the final 3D pose predictions.</li>
</ol>
</details>
<h2 id="4-predicting-poses-for-the-example-recording">4. Predicting Poses for the Example Recording</h2>
<p>If you haven't already you should now download our <strong><a href="https://zenodo.org/record/6515085/files/Example_Recording.zip?download=1">example recording</a></strong>.</p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio"><input id="__tabbed_3_2" name="__tabbed_3" type="radio"><div class="tabbed-labels"><label for="__tabbed_3_1">GUI</label><label for="__tabbed_3_2">CLI</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>Once you have the example recording saved on your computer all you need to do is launch the JARVIS GUI and navigate to the <span style="color:#63a31f">Predict3D</span> menu as shown below. Here you will have to specify a couple of things:</p>
<ul>
<li><strong>Path of recording directory</strong> is the path of the example recording you just downloaded, it should include the 'Example_Recording' directory.</li>
<li><strong>Weights for CenterDetect / HybridNet</strong> lets you specify which weights you want to use. If you have trained models yourself you can leave them at 'latest'. If you didn't train the network yourself you will have to put the path of the pretrained weights here. They can be found in the 'pretrained' directory inside your 'JARVIS-Hybridnet' folder.</li>
<li><strong>Start Frame &amp; Number Frames</strong> let you select on which part of the recording you want to run the prediction. For quick results set 'Number of Frames' to 1000. To predict until the end of the recording set it to -1.</li>
</ul>
<p>Once all those settings are correct, press the  <span style="color:#63a31f">Predict</span> button and wait for the progress bar to fill up as shown below.</p>
<p><a class="glightbox" href="../../assets/gifs/getting_started/gui_pred.gif"><img alt="Predicting using the GUI" class="center rounded" src="../../assets/gifs/getting_started/gui_pred.gif" width="90%"/></a></p>
</div>
<div class="tabbed-block">
<p>Once you have the example recording saved on your computer all you need to do is launch the JARVIS CLI and select <span style="color:#63a31f">Predict3D</span> in the <span style="color:#63a31f">Predict</span> menu as shown below. Here you will have to specify a couple of things:</p>
<ul>
<li>The <strong>Recordings Path</strong> is the path of the example recording you just downloaded, it should include the 'Example_Recording' directory.</li>
<li>Select <span style="color:#63a31f">No</span> for using <b>TensorRT acceleration</b> for now. If you installed the optional TensorRT packages this lets speed up predictions using NVIDIAs <a href="https://developer.nvidia.com/tensorrt">TensorRT</a> library. Compiling the TRT models takes quite some time though.</li>
<li>If you have trained models yourself you can use the most recently saved weights. Otherwise you will have to specify the path of the pretrained weights for the CenterDetect and the HybridNet networks here. They can be found in the 'pretrained' directory inside your 'JARVIS-Hybridnet' folder.</li>
<li>Select <span style="color:#63a31f">No</span> when asked if you want to use a <strong>calibration that is not in the trainingset</strong>.</li>
<li>To quickly get some results also select <span style="color:#63a31f">No</span> when asked wether you want to <strong>predict for the whole video</strong></li>
<li><strong>Start Frame &amp; Number of Frames</strong> let you select on which part of the recording you want to run the prediction. For quick results set 'Number of Frames' to 1000, to predict until the end of the recording set it to -1.</li>
</ul>
<p>After answering all the prompts you should see a progress bar filling up as shown below.</p>
<p><a class="glightbox" href="../../assets/gifs/getting_started/cli_pred.gif"><img alt="Predicting using the CLI" class="center rounded" src="../../assets/gifs/getting_started/cli_pred.gif" width="90%"/></a></p>
</div>
</div>
</input></input></div>
<p>Once the process is finished you will find a directory with a current timestamp in the projects folder under <span style="color:#63a31f">predictions</span>. That folder contains a 'data3D.csv' file that contains the 3D coordinates and their corresponding confidences for every point in time. The directory also contains a '.yaml' file that holds some information necessary for creating videos from your predictions.</p>
<h3 id="5-creating-annotated-videos-from-your-predictions">5. Creating Annotated Videos from Your Predictions</h3>
<p>The easiest way to check the quality of the predictions you just created is looking at annotated videos. For the 3D predictions those videos are created by projecting the 3D coordinates of the keypoints back into all available camera perspectives.  </p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:2"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio"><input id="__tabbed_4_2" name="__tabbed_4" type="radio"><div class="tabbed-labels"><label for="__tabbed_4_1">GUI</label><label for="__tabbed_4_2">CLI</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p>In the GUI navigate to the <span style="color:#63a31f">Visualization</span> menu as shown below. Here the right prediction directory should already be selected. If you want you can remove or add cameras from the list of cameras for which you want to create annotated videos. You can now click <span style="color:#63a31f">Create Video</span> as shown below. 
If everything is set correctly you should find a directory containing your freshly labeled videos in the project directory after the progress bar is filled up.</p>
<p><a class="glightbox" href="../../assets/gifs/getting_started/gui_vid.gif"><img alt="Creating Videos using the GUI" class="center rounded" src="../../assets/gifs/getting_started/gui_vid.gif" width="90%"/></a></p>
</div>
<div class="tabbed-block">
<p>Navigate to the <span style="color:#63a31f">Visualize Menu</span> after launching the JARVIS CLI. After selecting <span style="color:#63a31f">Create Videos 3D</span> and the Example_Project you should be able to select the Predictions_3D directory that you created in the last step. If you want you can now select and deselect all the cameras that will be used to create your annotated videos.
If everything is set correctly you should find a directory containing your freshly labeled videos in the project directory after the progress bar is filled up.</p>
<p><a class="glightbox" href="../../assets/gifs/getting_started/cli_vid.gif"><img alt="Creating Videos using the CLI" class="center rounded" src="../../assets/gifs/getting_started/cli_vid.gif" width="90%"/></a></p>
</div>
</div>
</input></input></div>
<form class="md-feedback" hidden="" name="feedback">
<fieldset>
<legend class="md-feedback__title">
        Was this page helpful?
      </legend>
<div class="md-feedback__inner">
<div class="md-feedback__list">
<button class="md-feedback__icon md-icon" data-md-value="1" title="This page was helpful" type="submit">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81Z"></path></svg>
</button>
<button class="md-feedback__icon md-icon" data-md-value="0" title="This page could be improved" type="submit">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14Z"></path></svg>
</button>
</div>
<div class="md-feedback__note">
<div data-md-value="1" hidden="">
              
              
                
              
              
                Thanks for your feedback!
              
            </div>
<div data-md-value="0" hidden="">
              
              
                
              
              
                

Thanks for your feedback! Help us improve this page by using our <a href="..." target="_blank">feedback form</a>.
              
            </div>
</div>
</div>
</fieldset>
</form>
</article>
</div>
</div>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: 1. Introduction" class="md-footer__link md-footer__link--prev" href="../1_introduction/" rel="prev">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</div>
<div class="md-footer__title">
<div class="md-ellipsis">
<span class="md-footer__direction">
                Previous
              </span>
              1. Introduction
            </div>
</div>
</a>
<a aria-label="Next: 3. Creating a new Trainingset" class="md-footer__link md-footer__link--next" href="../3_creating_trainingset/" rel="next">
<div class="md-footer__title">
<div class="md-ellipsis">
<span class="md-footer__direction">
                Next
              </span>
              3. Creating a new Trainingset
            </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
<div class="md-copyright__highlight">
      © 2022 Timo Hüser
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/JARVIS-MoCap" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.1.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</a>
<a class="md-social__link" href="https://twitter.com/hueser_timo" rel="noopener" target="_blank" title="twitter.com">
<svg viewbox="0 0 512 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.1.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["content.code.annotate", "navigation.instant", "navigation.tracking"], "search": "../../assets/javascripts/workers/search.ecf98df9.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
<script src="../../assets/javascripts/bundle.9c69f0bc.min.js"></script>
<script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "width": "100%", "height": "auto", "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom"});})</script></body>
</html>